{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fmt0_KdcgcYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "# import torchvision as tv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4cg15oTysy9R",
        "outputId": "53e06756-edde-4cb5-a31c-922fa20c1d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5120, 100) (5120,)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Create dummy dataset\n",
        "\"\"\"\n",
        "BATCH_SIZE = 512\n",
        "NUM_DATA = BATCH_SIZE * 10\n",
        "NUM_CLASSES = 10\n",
        "DIM = 100\n",
        "LR = 1e-2\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "# if torch.cuda.is_available:\n",
        "#     DEVICE = \"cuda:0\"\n",
        "\n",
        "dummy_data = np.random.normal(size=(NUM_DATA, DIM)).astype(np.float32)\n",
        "# (NUM_CLASS - 1e-10) is to avoid the random variable is 10.\n",
        "dummy_label = np.random.uniform(0, NUM_CLASSES - 1e-10, size=(NUM_DATA,)).astype(int) # \n",
        "\n",
        "print(dummy_data.shape, dummy_label.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "N5ja7DXZKgmC"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transformations):\n",
        "        # data: which is composed of [xs, ys]\n",
        "        # where xs.shape = [size of total data, dimension]\n",
        "        # where ys.shape = [size of total data]\n",
        "\n",
        "        # transformations: [transformation] data augmentation for data\n",
        "\n",
        "        self.data = data\n",
        "        self.transformations = transformations\n",
        "\n",
        "        assert len(self.data) == len(self.transformations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ### TODO\n",
        "        # Return the tuple of data given the index\n",
        "        # That is, (x, y)\n",
        "        # if transformation is not None\n",
        "        # data_ = transformation(data_)\n",
        "        item = []\n",
        "        for _tfm, _data in zip(self.transformations, self.data):\n",
        "            if _tfm is None:\n",
        "                item.append(_data[index])\n",
        "            else:\n",
        "                item.append(_tfm(_data[index]))\n",
        "        return tuple(item)\n",
        "\n",
        "    def __len__(self):\n",
        "        ### TODO\n",
        "        # Return the size of the data\n",
        "        return self.data[0].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "HbptUzoVKiVp",
        "outputId": "38565999-5097-4c97-a710-10fc9dbed3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pass DataSet check\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Dataset check\n",
        "\"\"\"\n",
        "def check_dataset():\n",
        "    dset = MyDataset([dummy_data, dummy_label], [None, None])\n",
        "    num_data = 0\n",
        "\n",
        "    for data_ in dset:\n",
        "        \n",
        "        input_, label_ = data_\n",
        "        assert input_.shape == (DIM, )\n",
        "\n",
        "        num_data += 1\n",
        "\n",
        "    assert num_data == dummy_data.shape[0], \"Implementation of __len__ might be wrong\"\n",
        "\n",
        "    print(\"pass DataSet check\")\n",
        "\n",
        "check_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "X15GfH03SCrD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DataLoader implementation\n",
        "\"\"\"\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def getData_dataloader(x, y, batchSize):\n",
        "    # Return a dataloader object\n",
        "    x, y = torch.FloatTensor(x), torch.LongTensor(y)\n",
        "    \n",
        "    x_transformation = None\n",
        "\n",
        "    y_transformation = None\n",
        "\n",
        "    d = MyDataset([x, y], [x_transformation, y_transformation])\n",
        "\n",
        "    ### TODO \n",
        "    # Create a dataloader object and return it\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(d, batch_size=batchSize, shuffle=True, num_workers=2)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ZMD-XHj5R88F",
        "outputId": "664ba5d8-b84a-458e-ed0e-113575c06919"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 7148, 13992) exited unexpectedly",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "File \u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1135\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
            "\u001b[1;31mEmpty\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\general\\data_loader\\dataloader_handson.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=19'>20</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=20'>21</a>\u001b[0m         \u001b[39m# out of index in data loader\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=21'>22</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mImplementation of __len__ might be wrong\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=24'>25</a>\u001b[0m check_dataloader()\n",
            "\u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\general\\data_loader\\dataloader_handson.ipynb Cell 6\u001b[0m in \u001b[0;36mcheck_dataloader\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=6'>7</a>\u001b[0m num_data \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=8'>9</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data_ \u001b[39min\u001b[39;00m dloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=11'>12</a>\u001b[0m         input_, label_ \u001b[39m=\u001b[39m data_\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CinnamonBootcamp/2022GlobalBootcamp/general/data_loader/dataloader_handson.ipynb#ch0000005?line=13'>14</a>\u001b[0m         num_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m input_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1295\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1296\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1297\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1298\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[1;32md:\\CinnamonBootcamp\\2022GlobalBootcamp\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1147\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1146\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1149\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 7148, 13992) exited unexpectedly"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "DataLoader check\n",
        "\"\"\"\n",
        "\n",
        "def check_dataloader():\n",
        "    dloader = getData_dataloader(dummy_data, dummy_label, 32)\n",
        "    num_data = 0\n",
        "\n",
        "    try:\n",
        "        for data_ in dloader:\n",
        "            \n",
        "            input_, label_ = data_\n",
        "\n",
        "            num_data += input_.shape[0]\n",
        "\n",
        "        assert num_data == dummy_data.shape[0], \"Implementation of __len__ might be wrong\"\n",
        "\n",
        "        print(\"pass DataLoader check\")\n",
        "\n",
        "    except IndexError:\n",
        "        # out of index in data loader\n",
        "        print(\"Implementation of __len__ might be wrong\")\n",
        "\n",
        "\n",
        "check_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "CeGlvdEEvJi_",
        "outputId": "20bc400d-5133-4442-a60a-d7ccb92c0e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BaseModel(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Model\n",
        "\"\"\"\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "\n",
        "        dim = 32\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = BaseModel(DIM, NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "print(model)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Xxb5Luf8Z5rP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Create the optimizer and objective function\n",
        "\"\"\"\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "\"\"\"\n",
        "Evaluation metrics\n",
        "\"\"\"\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def genMetrics(trueY, predY):\n",
        "    \"\"\"\n",
        "    Return acc and auc\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(trueY, predY)\n",
        "    \n",
        "    return round(accuracy, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "J4WsmeeZgcYs",
        "outputId": "2d44e242-5864-49f3-d8a0-34890a113f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================TRAIN==============================\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "the average loss after completion of 1 epochs is 2.307\n",
            "acc: 0.094\n",
            "============================================================\n",
            "spend 0.095 s\n",
            "\n",
            "==============================TRAIN==============================\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "the average loss after completion of 2 epochs is 2.279\n",
            "acc: 0.142\n",
            "============================================================\n",
            "spend 0.070 s\n",
            "\n",
            "==============================TRAIN==============================\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "the average loss after completion of 3 epochs is 2.238\n",
            "acc: 0.177\n",
            "============================================================\n",
            "spend 0.198 s\n",
            "\n",
            "==============================TRAIN==============================\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "the average loss after completion of 4 epochs is 2.187\n",
            "acc: 0.206\n",
            "============================================================\n",
            "spend 0.069 s\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Data Module\n",
        "\"\"\" \n",
        "\n",
        "# Naive method\n",
        "def getData_naive(x, y, batchSize):\n",
        "    \"\"\"\n",
        "    Create a generator for loading data\n",
        "    \"\"\"\n",
        "\n",
        "    # shuffle the data\n",
        "    perm = np.arange(len(x))\n",
        "    np.random.shuffle(perm)\n",
        "    x = x[perm]\n",
        "    y = y[perm]\n",
        "\n",
        "    numBatches = len(x) // batchSize\n",
        "\n",
        "    x, y = torch.FloatTensor(x), torch.LongTensor(y)\n",
        "\n",
        "    for i in range(numBatches):\n",
        "        start = i * batchSize\n",
        "        end = start + batchSize\n",
        "        batchX = x[start: end]\n",
        "        batchY = y[start: end]\n",
        "\n",
        "        yield batchX, batchY\n",
        "\n",
        "###########################################################################################\n",
        "#### Start training\n",
        "###########################################################################################\n",
        "\n",
        "# You can use getData_naive to see the output of data\n",
        "getData = getData_dataloader\n",
        "\n",
        "# Decorator for computing time\n",
        "def print_time(func):\n",
        "    def decorated_func(*args, **kwargs):\n",
        "        s = time.time()\n",
        "        ret = func(*args, **kwargs)\n",
        "        e = time.time()\n",
        "\n",
        "        print(f\"spend {e - s:.3f} s\")\n",
        "        return ret\n",
        "\n",
        "    return decorated_func\n",
        "\n",
        "@print_time\n",
        "def train(train_data, epoch, model, loss_function, optimizer):\n",
        "    print(\"\\n\" + \"=\"*30 + \"TRAIN\" + \"=\"*30)\n",
        "    y_p = []\n",
        "    y_t = []\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    count = 0\n",
        "    # need a batch dataloader\n",
        "    for batch in getData(train_data[0], train_data[1], BATCH_SIZE):\n",
        "        input_data = batch[0].to(DEVICE)\n",
        "        target_data = batch[1].to(DEVICE)\n",
        "\n",
        "        y_pred = model(input_data)\n",
        "        print(y_pred.shape)\n",
        "        print(target_data.shape)\n",
        "        loss = loss_function(y_pred, target_data)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += loss.item()\n",
        "        #a better metric here\n",
        "        predictions = y_pred.data.max(1)[1].cpu().tolist()\n",
        "        y_p += predictions\n",
        "        y_t += target_data.tolist()\n",
        "        #a better metric here \n",
        "        count += 1\n",
        "        if count % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, iterations: {count}, loss: {loss.item():.3f}\")\n",
        "\n",
        "    print(f\"the average loss after completion of {epoch} epochs is {avg_loss/count:.3f}\")\n",
        "    acc = genMetrics(y_t, y_p)\n",
        "    print(f\"acc: {acc:.3f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(1, epochs+1):\n",
        "    train([dummy_data, dummy_label], epoch, model, loss_function, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY1HXRN6XcVv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dataloader_handson.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "881621f52f5e994ae267cd7db937900eaa9d03f22234e22f8521ed97ad90d703"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
